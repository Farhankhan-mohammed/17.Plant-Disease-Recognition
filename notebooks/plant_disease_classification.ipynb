{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Plant Disease Recognition Using MobileNet\n",
                "\n",
                "**MSc Data Science - Deep Learning Applications (CMP-L016)**\n",
                "\n",
                "**Project 17: Plant Disease Recognition Using MobileNet Variants**\n",
                "\n",
                "---\n",
                "\n",
                "**Author:** [Your Name]\n",
                "\n",
                "**Date:** December 2025"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 1. Setup and GPU Configuration"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "!pip install -q kagglehub"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import tensorflow as tf\n",
                "\n",
                "gpus = tf.config.list_physical_devices('GPU')\n",
                "if gpus:\n",
                "    try:\n",
                "        for gpu in gpus:\n",
                "            tf.config.experimental.set_memory_growth(gpu, True)\n",
                "        print(f\"GPU devices found: {len(gpus)}\")\n",
                "        for gpu in gpus:\n",
                "            print(f\"  - {gpu.name}\")\n",
                "    except RuntimeError as e:\n",
                "        print(e)\n",
                "else:\n",
                "    print(\"No GPU found. Please enable GPU in Runtime > Change runtime type > GPU\")\n",
                "\n",
                "print(f\"\\nTensorFlow Version: {tf.__version__}\")\n",
                "print(f\"Num GPUs Available: {len(tf.config.list_physical_devices('GPU'))}\")\n",
                "\n",
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
                "from tensorflow.keras.applications import MobileNetV2\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
                "from tensorflow.keras.optimizers import Adam\n",
                "from tensorflow.keras.preprocessing import image\n",
                "from sklearn.metrics import classification_report, confusion_matrix\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 2. Download Dataset"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import kagglehub\n",
                "\n",
                "path = kagglehub.dataset_download(\"karagwaanntreasure/plant-disease-detection\")\n",
                "print(\"Path to dataset files:\", path)"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "dataset_path = os.path.join(path, \"Dataset\")\n",
                "\n",
                "if not os.path.exists(dataset_path):\n",
                "    for root, dirs, files in os.walk(path):\n",
                "        for d in dirs:\n",
                "            if d == \"Dataset\":\n",
                "                dataset_path = os.path.join(root, d)\n",
                "                break\n",
                "        if os.path.exists(dataset_path):\n",
                "            break\n",
                "    else:\n",
                "        dataset_path = path\n",
                "\n",
                "print(f\"Dataset path: {dataset_path}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 3. Data Exploration"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "class_names = sorted([d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))])\n",
                "num_classes = len(class_names)\n",
                "\n",
                "print(f\"Number of classes: {num_classes}\")\n",
                "print(f\"\\nClass names:\")\n",
                "for i, name in enumerate(class_names):\n",
                "    print(f\"  {i+1}. {name}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "class_counts = {}\n",
                "for class_name in class_names:\n",
                "    class_path = os.path.join(dataset_path, class_name)\n",
                "    count = len([f for f in os.listdir(class_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
                "    class_counts[class_name] = count\n",
                "\n",
                "df_counts = pd.DataFrame(list(class_counts.items()), columns=['Class', 'Count'])\n",
                "df_counts = df_counts.sort_values('Count', ascending=False)\n",
                "\n",
                "print(f\"Total images: {df_counts['Count'].sum()}\")\n",
                "print(f\"\\nClass distribution:\")\n",
                "print(df_counts.to_string(index=False))"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "plt.figure(figsize=(14, 8))\n",
                "colors = plt.cm.viridis(np.linspace(0, 1, len(df_counts)))\n",
                "bars = plt.barh(df_counts['Class'], df_counts['Count'], color=colors)\n",
                "plt.xlabel('Number of Images', fontsize=12)\n",
                "plt.ylabel('Disease Class', fontsize=12)\n",
                "plt.title('Distribution of Images Across Disease Classes', fontsize=14, fontweight='bold')\n",
                "plt.gca().invert_yaxis()\n",
                "for bar, count in zip(bars, df_counts['Count']):\n",
                "    plt.text(bar.get_width() + 10, bar.get_y() + bar.get_height()/2, str(count), va='center', fontsize=9)\n",
                "plt.tight_layout()\n",
                "plt.savefig('class_distribution.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "n_cols = 5\n",
                "n_rows = (len(class_names) + n_cols - 1) // n_cols\n",
                "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 3*n_rows))\n",
                "axes = axes.flatten()\n",
                "\n",
                "for idx, class_name in enumerate(class_names):\n",
                "    class_path = os.path.join(dataset_path, class_name)\n",
                "    images = [f for f in os.listdir(class_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
                "    if images:\n",
                "        img_path = os.path.join(class_path, images[0])\n",
                "        img = plt.imread(img_path)\n",
                "        axes[idx].imshow(img)\n",
                "        short_name = class_name.replace('_', '\\n')[:30]\n",
                "        axes[idx].set_title(short_name, fontsize=8)\n",
                "    axes[idx].axis('off')\n",
                "\n",
                "for idx in range(len(class_names), len(axes)):\n",
                "    axes[idx].axis('off')\n",
                "\n",
                "plt.suptitle('Sample Images from Each Disease Class', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.savefig('sample_images.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 4. Data Preprocessing"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "img_size = (224, 224)\n",
                "batch_size = 32\n",
                "\n",
                "datagen = ImageDataGenerator(\n",
                "    rescale=1./255,\n",
                "    validation_split=0.2,\n",
                "    shear_range=0.2,\n",
                "    zoom_range=0.2,\n",
                "    horizontal_flip=True\n",
                ")\n",
                "\n",
                "train_data = datagen.flow_from_directory(\n",
                "    dataset_path,\n",
                "    target_size=img_size,\n",
                "    batch_size=batch_size,\n",
                "    class_mode='categorical',\n",
                "    subset='training'\n",
                ")\n",
                "\n",
                "val_data = datagen.flow_from_directory(\n",
                "    dataset_path,\n",
                "    target_size=img_size,\n",
                "    batch_size=batch_size,\n",
                "    class_mode='categorical',\n",
                "    subset='validation'\n",
                ")\n",
                "\n",
                "num_classes = train_data.num_classes\n",
                "print(f\"\\nNumber of classes: {num_classes}\")\n",
                "print(f\"Training samples: {train_data.samples}\")\n",
                "print(f\"Validation samples: {val_data.samples}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "fig, axes = plt.subplots(2, 4, figsize=(14, 7))\n",
                "axes = axes.flatten()\n",
                "batch = next(train_data)\n",
                "images, labels = batch\n",
                "class_indices = {v: k for k, v in train_data.class_indices.items()}\n",
                "\n",
                "for i in range(8):\n",
                "    axes[i].imshow(images[i])\n",
                "    label_idx = np.argmax(labels[i])\n",
                "    class_name = class_indices[label_idx]\n",
                "    short_name = class_name.replace('_', ' ')[:25]\n",
                "    axes[i].set_title(f'{short_name}', fontsize=9)\n",
                "    axes[i].axis('off')\n",
                "\n",
                "plt.suptitle('Augmented Training Images', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.savefig('augmented_samples.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 5. MobileNetV2 Transfer Learning Model"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
                "base_model.trainable = False\n",
                "\n",
                "model = Sequential([\n",
                "    base_model,\n",
                "    GlobalAveragePooling2D(),\n",
                "    Dense(128, activation='relu'),\n",
                "    Dropout(0.3),\n",
                "    Dense(num_classes, activation='softmax')\n",
                "])\n",
                "\n",
                "model.compile(\n",
                "    optimizer=Adam(learning_rate=0.0001),\n",
                "    loss='categorical_crossentropy',\n",
                "    metrics=['accuracy']\n",
                ")\n",
                "\n",
                "model.summary()"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "history = model.fit(\n",
                "    train_data,\n",
                "    validation_data=val_data,\n",
                "    epochs=15\n",
                ")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
                "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
                "plt.title('Model Accuracy')\n",
                "plt.xlabel('Epoch')\n",
                "plt.ylabel('Accuracy')\n",
                "plt.legend()\n",
                "plt.savefig('mobilenet_accuracy.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "plt.plot(history.history['loss'], label='Train Loss')\n",
                "plt.plot(history.history['val_loss'], label='Val Loss')\n",
                "plt.title('Model Loss')\n",
                "plt.xlabel('Epoch')\n",
                "plt.ylabel('Loss')\n",
                "plt.legend()\n",
                "plt.savefig('mobilenet_loss.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 6. Model Evaluation"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "val_loss, val_acc = model.evaluate(val_data, verbose=0)\n",
                "print(f\"Validation Loss: {val_loss:.4f}\")\n",
                "print(f\"Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "val_data.reset()\n",
                "predictions = model.predict(val_data, verbose=1)\n",
                "predicted_classes = np.argmax(predictions, axis=1)\n",
                "true_classes = val_data.classes\n",
                "class_labels = list(val_data.class_indices.keys())"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "print(\"\\nClassification Report:\")\n",
                "print(\"=\"*80)\n",
                "report = classification_report(true_classes, predicted_classes, target_names=class_labels, digits=4)\n",
                "print(report)\n",
                "\n",
                "with open('classification_report.txt', 'w') as f:\n",
                "    f.write(\"Classification Report - MobileNetV2\\n\")\n",
                "    f.write(\"=\"*80 + \"\\n\")\n",
                "    f.write(report)"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "cm = confusion_matrix(true_classes, predicted_classes)\n",
                "\n",
                "plt.figure(figsize=(16, 14))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
                "plt.title('Confusion Matrix - MobileNetV2', fontsize=14, fontweight='bold')\n",
                "plt.xlabel('Predicted Label', fontsize=12)\n",
                "plt.ylabel('True Label', fontsize=12)\n",
                "plt.xticks(rotation=90, fontsize=8)\n",
                "plt.yticks(rotation=0, fontsize=8)\n",
                "plt.tight_layout()\n",
                "plt.savefig('confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "per_class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
                "accuracy_df = pd.DataFrame({\n",
                "    'Class': class_labels,\n",
                "    'Accuracy': per_class_accuracy,\n",
                "    'Samples': cm.sum(axis=1)\n",
                "}).sort_values('Accuracy')\n",
                "\n",
                "print(\"Per-Class Accuracy (sorted):\")\n",
                "print(accuracy_df.to_string(index=False))\n",
                "\n",
                "plt.figure(figsize=(12, 8))\n",
                "colors = ['red' if acc < 0.8 else 'orange' if acc < 0.9 else 'green' for acc in accuracy_df['Accuracy']]\n",
                "plt.barh(accuracy_df['Class'], accuracy_df['Accuracy'], color=colors)\n",
                "plt.axvline(x=0.9, color='green', linestyle='--', label='90% threshold')\n",
                "plt.axvline(x=0.8, color='orange', linestyle='--', label='80% threshold')\n",
                "plt.xlabel('Accuracy', fontsize=12)\n",
                "plt.ylabel('Disease Class', fontsize=12)\n",
                "plt.title('Per-Class Accuracy', fontsize=14, fontweight='bold')\n",
                "plt.legend()\n",
                "plt.tight_layout()\n",
                "plt.savefig('per_class_accuracy.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 7. Sample Predictions"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "val_data.reset()\n",
                "batch = next(val_data)\n",
                "images, labels = batch\n",
                "preds = model.predict(images, verbose=0)\n",
                "class_indices = {v: k for k, v in val_data.class_indices.items()}\n",
                "\n",
                "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
                "axes = axes.flatten()\n",
                "\n",
                "for i in range(12):\n",
                "    axes[i].imshow(images[i])\n",
                "    true_idx = np.argmax(labels[i])\n",
                "    pred_idx = np.argmax(preds[i])\n",
                "    confidence = preds[i][pred_idx] * 100\n",
                "    true_label = class_indices[true_idx].replace('_', ' ')[:25]\n",
                "    pred_label = class_indices[pred_idx].replace('_', ' ')[:25]\n",
                "    color = 'green' if true_idx == pred_idx else 'red'\n",
                "    axes[i].set_title(f'True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.1f}%', fontsize=9, color=color)\n",
                "    axes[i].axis('off')\n",
                "\n",
                "plt.suptitle('Sample Predictions (Green=Correct, Red=Incorrect)', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.savefig('sample_predictions.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 8. Save Model"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "model.save('plant_disease_mobilenetv2.h5')\n",
                "print(\"Model saved as 'plant_disease_mobilenetv2.h5'\")\n",
                "\n",
                "import json\n",
                "with open('class_labels.json', 'w') as f:\n",
                "    json.dump(class_labels, f, indent=2)\n",
                "print(\"Class labels saved as 'class_labels.json'\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 9. Test Prediction Function"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "def predict_image(img_path):\n",
                "    img = image.load_img(img_path, target_size=img_size)\n",
                "    img_array = image.img_to_array(img) / 255.0\n",
                "    img_array = np.expand_dims(img_array, axis=0)\n",
                "    prediction = model.predict(img_array)\n",
                "    predicted_class = class_labels[np.argmax(prediction)]\n",
                "    confidence = np.max(prediction) * 100\n",
                "    print(f\"Predicted: {predicted_class} ({confidence:.2f}% confidence)\")\n",
                "    return predicted_class, confidence"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "test_class = class_names[0]\n",
                "test_class_path = os.path.join(dataset_path, test_class)\n",
                "test_images = [f for f in os.listdir(test_class_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
                "if test_images:\n",
                "    test_img_path = os.path.join(test_class_path, test_images[0])\n",
                "    print(f\"Testing on: {test_img_path}\")\n",
                "    predict_image(test_img_path)"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 10. Summary"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"PROJECT COMPLETE\")\n",
                "print(\"=\"*80)\n",
                "print(f\"\\nDataset: {train_data.samples + val_data.samples} images across {num_classes} classes\")\n",
                "print(f\"Training samples: {train_data.samples}\")\n",
                "print(f\"Validation samples: {val_data.samples}\")\n",
                "print(f\"\\nFinal MobileNetV2 Results:\")\n",
                "print(f\"  Validation Accuracy: {val_acc*100:.2f}%\")\n",
                "print(f\"  Validation Loss: {val_loss:.4f}\")\n",
                "print(f\"\\nFiles Generated:\")\n",
                "print(\"  - plant_disease_mobilenetv2.h5\")\n",
                "print(\"  - class_labels.json\")\n",
                "print(\"  - class_distribution.png\")\n",
                "print(\"  - sample_images.png\")\n",
                "print(\"  - augmented_samples.png\")\n",
                "print(\"  - mobilenet_accuracy.png\")\n",
                "print(\"  - mobilenet_loss.png\")\n",
                "print(\"  - confusion_matrix.png\")\n",
                "print(\"  - per_class_accuracy.png\")\n",
                "print(\"  - sample_predictions.png\")\n",
                "print(\"  - classification_report.txt\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        }
    ]
}